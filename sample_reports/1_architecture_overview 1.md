# Architecture Overview
**Target:** `/root/streamlit-agent-main/streamlit_agent`
**Analysis Date:** February 22, 2026
**Analyst:** UC Recon â€” Deep Forensics Mode

---

## 1. Executive Summary

`streamlit-agent` is a **collection of 9 independent Streamlit single-page applications** that each demonstrate a distinct LangChain integration pattern. There is no shared application server, no routing layer, no authentication middleware, and no central orchestration process. Each `.py` file is both entry point and complete application. The Docker default entrypoint is `chat_pandas_df.py`, but any module can be launched independently.

The architecture is **flat and modular**: most modules are standalone pages; two (`mrkl_demo.py`) consume internal helpers from `callbacks/` and `clear_results.py`.

---

## 2. System Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               PRESENTATION LAYER                        â”‚
â”‚  Streamlit UI (st.chat_input, st.sidebar, st.chat_messageâ”‚
â”‚  st.file_uploader, st.form, st.selectbox, st.expander)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ st.session_state / st.secrets
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               AGENT / CHAIN LAYER                       â”‚
â”‚  LangChain Agents (SQL, Pandas REPL, ConversationalChat)â”‚
â”‚  LangChain Chains (ConversationalRetrieval, ConvChain,  â”‚
â”‚    SQLDatabaseChain, LLMMathChain)                      â”‚
â”‚  LangChain Hub (hwchase17/react prompt pulled at runtime)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               TOOL / MEMORY LAYER                       â”‚
â”‚  Tools: DuckDuckGoSearch, PythonAstREPLTool (implicit), â”‚
â”‚    SQLDatabaseToolkit, LLMMathChain (as Tool)           â”‚
â”‚  Memory: ConversationBufferMemory, StreamlitChatHistory  â”‚
â”‚  VectorStore: DocArrayInMemorySearch (in-process)       â”‚
â”‚  Embeddings: HuggingFaceEmbeddings (all-MiniLM-L6-v2)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               MODEL LAYER                               â”‚
â”‚  OpenAI: ChatOpenAI (gpt-3.5-turbo, gpt-3.5-turbo-0613)â”‚
â”‚  OpenAI: OpenAI (text completion, temperature=0)        â”‚
â”‚  API keys accepted at runtime via sidebar / st.secrets  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               PERSISTENCE / EXTERNAL LAYER              â”‚
â”‚  SQLite: Chinook.db (local, read-only for local mode)   â”‚
â”‚  User-supplied DB URI (arbitrary RDBMS via SQLAlchemy)  â”‚
â”‚  Pickle files: runs/alanis.pickle, runs/leo.pickle      â”‚
â”‚  Temp filesystem: tempfile.TemporaryDirectory (PDFs)    â”‚
â”‚  LangSmith: https://api.smith.langchain.com             â”‚
â”‚  LangChain Hub: hub.pull() at runtime                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Design Patterns

| Pattern | Files Using It | Notes |
|---|---|---|
| **Streamlit Script-as-App** | All 9 modules | No `if __name__ == '__main__'` â€” Streamlit re-executes entire script on each interaction |
| **LangChain LCEL (pipe operator)** | `basic_memory.py` | `prompt \| ChatOpenAI(...)` chain composition |
| **Legacy LangChain Chains** | `chat_with_documents.py`, `simple_feedback.py`, `chat_with_sql_db.py`, `mrkl_demo.py` | Uses deprecated `langchain.chat_models`, `langchain.chains` |
| **AgentExecutor pattern** | `chat_pandas_df.py`, `chat_with_sql_db.py`, `search_and_chat.py`, `mrkl_demo.py`, `minimal_agent.py` | Wraps tools + LLM in autonomous loop |
| **Callback-driven streaming** | `basic_streaming.py`, `chat_with_documents.py`, `mrkl_demo.py`, `search_and_chat.py` | `BaseCallbackHandler` subclasses push tokens to UI |
| **Session-state memory** | `basic_memory.py`, `search_and_chat.py`, `simple_feedback.py`, `chat_with_documents.py` | `StreamlitChatMessageHistory` wraps `st.session_state` |
| **@st.cache_resource** | `chat_with_documents.py`, `chat_with_sql_db.py` | Expensive resources (DB, retriever) cached across reruns |
| **@st.cache_data** | `chat_pandas_df.py`, `simple_feedback.py` | Data objects cached with TTL |
| **Pickle-based session replay** | `mrkl_demo.py` + `capturing_callback_handler.py` | Saved LangChain callback streams replayed from disk |
| **RAG (Retrieval-Augmented Generation)** | `chat_with_documents.py` | PDF â†’ chunked â†’ embedded â†’ in-memory vector DB â†’ ConversationalRetrievalChain |

---

## 4. Module Relationships

```
streamlit_agent/
â”œâ”€â”€ basic_memory.py            [standalone]
â”œâ”€â”€ basic_streaming.py         [standalone]
â”œâ”€â”€ chat_pandas_df.py          [standalone] â† Docker default
â”œâ”€â”€ chat_with_documents.py     [standalone]
â”œâ”€â”€ chat_with_sql_db.py        [standalone]
â”œâ”€â”€ clear_results.py           [utility â€” imported by mrkl_demo.py]
â”œâ”€â”€ minimal_agent.py           [standalone]
â”œâ”€â”€ mrkl_demo.py               [imports: callbacks/capturing_callback_handler.py,
â”‚                               clear_results.py]
â”œâ”€â”€ search_and_chat.py         [standalone]
â”œâ”€â”€ simple_feedback.py         [standalone]
â””â”€â”€ callbacks/
    â””â”€â”€ capturing_callback_handler.py  [utility â€” imported by mrkl_demo.py]
```

Only `mrkl_demo.py` imports internal helpers. All other modules are fully self-contained.

---

## 5. Security Posture

| Domain | Assessment |
|---|---|
| **Authentication** | âŒ NONE â€” no login, session tokens, or access control on any page |
| **API Key Management** | âš ï¸ WEAK â€” keys accepted in sidebar text inputs; stored in `st.session_state`; some fall back to `st.secrets` |
| **Input Validation** | âŒ NONE â€” user prompts passed directly to LLM agents without sanitization |
| **SQL Injection** | âš ï¸ NOTED in code comments â€” uses LangChain's SQL agent which is prompt-injectable |
| **Arbitrary Code Execution** | ğŸ”´ CRITICAL â€” `chat_pandas_df.py` uses `PythonAstREPLTool`; code acknowledged in warning |
| **Path Traversal** | âš ï¸ MEDIUM â€” uploaded file names used directly in `os.path.join` without sanitization |
| **SSRF** | âš ï¸ MEDIUM â€” user-controlled DB URI passed directly to `SQLDatabase.from_uri()` |
| **Pickle Deserialization** | ğŸ”´ HIGH â€” `pickle.load()` on user-reachable path in `capturing_callback_handler.py` |
| **Dependency Security** | âš ï¸ MEDIUM â€” `langchain-experimental` included (explicitly risky per LangChain docs) |
| **External Telemetry** | âš ï¸ INFO â€” `simple_feedback.py` sends traces + feedback to `api.smith.langchain.com` |

**Overall Posture: HIGH RISK** â€” This codebase was designed as demo/educational material, not production-hardened software. It has no authentication, no input sanitization, and at least two critical RCE pathways.

---

## 6. Runtime Environment

- **Python:** â‰¥3.10, <4.0 (Dockerfile uses 3.11)
- **Framework:** Streamlit â‰¥1.26
- **Package Manager:** Poetry
- **Container:** Docker (python:3.11-buster builder â†’ python:3.11-slim-buster runtime)
- **Default Port:** 8051
- **LLM Provider:** OpenAI (API key required at runtime)
- **No environment variables baked into image** â€” all secrets are runtime inputs
